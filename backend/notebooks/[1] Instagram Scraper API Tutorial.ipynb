{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Scraper API\n",
    "This notebook shows how to use Instagram Scraper API implementated by [realsirjoe](https://github.com/realsirjoe/instagram-scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about these\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some libraries that are useful for us to process and visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy is for numerical calculation\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib is for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# we need this line to embed the plot in the notebook\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instagram API that we are using\n",
    "from igramscraper.instagram import Instagram\n",
    "\n",
    "# we use \"sleep\" to control the speed we access instagram website.\n",
    "# If this is too low, instagram will block us\n",
    "from time import sleep  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create instagram object for scraping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instagram object, its important to set the sleeping time sufficiently high\n",
    "instagram = Instagram(sleep_between_requests=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get posts related to a hashtag as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medias = instagram.get_current_top_medias_by_tag_name('london')\n",
    "\n",
    "# returns a list of media\n",
    "medias = instagram.get_medias_by_tag('london', count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the first item in the list\n",
    "media = medias[0]\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests library allows us to load content from URL \n",
    "import requests\n",
    "# BytesIO is a nice wrapper to contain raw byte data read from the URL\n",
    "from io import BytesIO\n",
    "# we use PIL to \"load\" images from a URL\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "def get_thumbnail(url, imsize=None):\n",
    "    \"\"\" download the image and return a numpy array representing the image\n",
    "    \n",
    "    Args:\n",
    "      url (str): URL to download the image from.\n",
    "      (optional) imsize (tuple): Resize image, specify in (nx, ny) format.\n",
    "    Returns:\n",
    "       (np.ndarray): the downloaded image which is resized \n",
    "    \"\"\"\n",
    "    # fetch the rawdata from URL\n",
    "    response = requests.get(url)\n",
    "    # convert rawdata into an image\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # resize the image using bicubic interpolation\n",
    "    if imsize:\n",
    "        img = img.resize(imsize, PIL.Image.BICUBIC)\n",
    "    # convert to numpy array so we can process \n",
    "    img_array = np.array(img)\n",
    "    # return the numpy array\n",
    "    return img_array\n",
    "\n",
    "def show_thumbnail(img, media_caption):\n",
    "    \"\"\" Show thumbnail using matplotlib \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{media_caption[:20]}...')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = get_thumbnail(medias[0].image_high_resolution_url)\n",
    "\n",
    "show_thumbnail(thumbnail, media.caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! let's iterate through the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for media in medias:\n",
    "    thumbnail = get_thumbnail(media.image_high_resolution_url)\n",
    "    show_thumbnail(thumbnail, media.caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best way for us to get the data we want is to scrape the website using `instagram.get_medias_by_tag('london', count=100)`\n",
    "- The above function only gives you basic media information (caption, comments, #likes, etc.) and does not include location information\n",
    "- In order to get the location information, we can do:\n",
    "\n",
    "  (1) extract media id using the above function,\n",
    "  \n",
    "  (2) extract the media content using the media id and `instagram.get_media_by_id` function, \n",
    "  \n",
    "  (3) extract location information that is contained in the media content\n",
    "\n",
    "\n",
    "- Not the best workaround we expected. At least we can get some data we wanted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = instagram.get_media_by_id('2183856998075057001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.location_id, media.location_name, media.location_slug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note] \n",
    "- We wanted to extract the geographical coordinate from the media. This seems nontrivial and cannot be done within Instagram. We would need to think an alternatives to map [`location name`] -> [`(latitude, longitude)`]\n",
    "- Each location has corresponding `location_id`. For example, `location_id` of \"london\" is 213385402."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = instagram.get_location_by_id(213385402)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some major locations do seem to contain (latitude, longitude) information though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: Hacking Tutorial\n",
    "\n",
    "- What is actually happening under the hood of this instagram API?\n",
    "- We can find out by walking through the [code](https://github.com/realsirjoe/instagram-scraper/blob/2d5fb53f1a92add34a8dbcf129708ed15d478190/igramscraper/instagram.py).\n",
    "\n",
    "For example, let's check what happens when I run `instagram.get_account('tserence')`.\n",
    "- If I go to the source code, I can check what `get_account` function does: [Line1070](https://github.com/realsirjoe/instagram-scraper/blob/2d5fb53f1a92add34a8dbcf129708ed15d478190/igramscraper/instagram.py#L1070). In there, I find that the code looks like this:\n",
    "```python\n",
    "class Instagram:\n",
    "    # ...\n",
    "    \n",
    "    def get_account(self, username):\n",
    "        \"\"\"\n",
    "        :param username: username\n",
    "        :return: Account\n",
    "        \"\"\"\n",
    "        time.sleep(self.sleep_between_requests)\n",
    "        response = self.__req.get(endpoints.get_account_page_link(\n",
    "            username), headers=self.generate_headers(self.user_session))\n",
    "\n",
    "        if Instagram.HTTP_NOT_FOUND == response.status_code:\n",
    "            raise InstagramNotFoundException(\n",
    "                'Account with given username does not exist.')\n",
    "\n",
    "        if Instagram.HTTP_OK != response.status_code:\n",
    "            raise InstagramException.default(response.text,\n",
    "                                             response.status_code)\n",
    "\n",
    "        user_array = Instagram.extract_shared_data_from_body(response.text)\n",
    "\n",
    "        if user_array['entry_data']['ProfilePage'][0]['graphql']['user'] is None:\n",
    "            raise InstagramNotFoundException(\n",
    "                'Account with this username does not exist')\n",
    "\n",
    "        return Account(\n",
    "            user_array['entry_data']['ProfilePage'][0]['graphql']['user'])\n",
    "```\n",
    "\n",
    "- From this code, I can deduce that the code has 3 parts:\n",
    "\n",
    "  - the part which gets the page content using `self.__req.get(...)`,\n",
    "  \n",
    "  - the part which converts the raw `response` to JSON object which only contains the juicy part using `Instagram.extract_shared_data_from_body(response.text)`\n",
    "  \n",
    "  - the part which converts the result to an `Account` object\n",
    "  \n",
    "- The remainder of the code is checking if the HTTP request method was successful, and raises `Exception`'s when this fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you press `Ctrl+Click` and press `inspect`, then you can find the source html of the website. All website is simply rendering this html. Scraper works the same way -- it literally loads this html and obtain the html components that you want and download them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the obtained HTML body is converted into `json` format, let's actually see how this looks like. In order to step through the instagram API, I will replicate the behaviour of `instagram.get_account` in this notebook below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igramscraper.instagram import endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a request session so we can access the URL's\n",
    "import requests  # <-- already imported above so you actually don't need this. I put it here for clarity.\n",
    "__req = requests.session()\n",
    "\n",
    "# replicate the call to `instagram.get_account`\n",
    "username = 'tserence'\n",
    "response = __req.get(\n",
    "    endpoints.get_account_page_link(username),\n",
    "    headers=instagram.generate_headers(instagram.user_session),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the request session to avoid memory leak... \n",
    "# Instagram API doesn't do this! Potential problem...\n",
    "__req.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to JSON\n",
    "user_array = Instagram.extract_shared_data_from_body(response.text)\n",
    "# I know the extracts the information from \n",
    "# `user_array['entry_data']['ProfilePage'][0]['graphql']['user']`\n",
    "# to get the user information, so lets see what is happening here.\n",
    "user_json =  user_array['entry_data']['ProfilePage'][0]['graphql']['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what attributes are in this\n",
    "user_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! Now we know what kind of internal information Instagram is using to render their content. Let's see some of the interesting contents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terence_profile_pic = get_thumbnail(user_json['profile_pic_url'], imsize=(200, 200))\n",
    "show_thumbnail(terence_profile_pic, 'Terence Profile Pic!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\n",
    "    'full_name',\n",
    "    'is_private',\n",
    "    'biography',\n",
    "    'has_blocked_viewer',\n",
    "]:\n",
    "    print(f'[{key}]: {user_json[key]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Terence has no `has_blocked_viewer`'s, what a great guy! (WOW Instagram, what kind of information are you returning!?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
