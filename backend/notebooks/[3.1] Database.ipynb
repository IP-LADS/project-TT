{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project TT Instagram Database\n",
    "- This notebook shows how to create a database from a bunch of instagram media posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about these\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "PROJECT_TT_ROOT = os.path.abspath('../..')  # project root\n",
    "sys.path.append('..')  # add backend to python path\n",
    "\n",
    "import pathlib\n",
    "from time import sleep\n",
    "\n",
    "from igramscraper.instagram import Instagram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  # pandas is a library that helps us manage spreadsheet-like data efficiently\n",
    "from PIL import Image\n",
    "%matplotlib inline  \n",
    "\n",
    "# import previously defined functions\n",
    "from core.utils import get_thumbnail, show_thumbnail, imresize\n",
    "from core.instagram import get_media_by_url\n",
    "from core.envs import IMAGE_DIR, THUMBNAIL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram = Instagram(sleep_between_requests=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our database is small, we will store our data as [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) file.\n",
    "\n",
    "Let's create a dataset with 50 instagram posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias = instagram.get_medias_by_tag('london', count=50)  # this will take some time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that they are scraped, lets save them in a database.\n",
    "- We will first create pandas.Dataframe and put it into table-like format\n",
    "- We will then use pandas functionality `to_csv` to generate the csv file representing our database\n",
    "\n",
    "Recall the attributes we wanted to save from \"[2] Instagram Data Attributes.ipynb\". Note that currently there is no \"location\" information -- we will worry about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'media_id', \n",
    "    'media_code', \n",
    "    'media_link', \n",
    "    'user_id',\n",
    "    'username',\n",
    "    'user_full_name',\n",
    "    'type', \n",
    "    'created_time',\n",
    "    'likes_count', \n",
    "    'img_thumbnail_url', \n",
    "    'img_highres_url', \n",
    "    'carousel_ids',\n",
    "    'carousel_types',\n",
    "    'carousel_thumbnail_urls', \n",
    "    'carousel_highres_urls', \n",
    "    'caption',\n",
    "    'comments_count',\n",
    "    'comments',\n",
    "    'location_id',\n",
    "    'location_name',\n",
    "    'location_slug',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function which will convert the \"Media\" object (that instagram scraper API is using to represent data) to a list of attributes that we are interested in, specified by `columns` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_to_row(media):\n",
    "    \"\"\" Convert media object read from instagram scrape API \n",
    "    to a row in dataset, with default values.\n",
    "    \"\"\"\n",
    "    if hasattr(media, 'thumbnail_src'):\n",
    "        media.image_thumbnail_url = media.thumbnail_src\n",
    "        \n",
    "    # check if media has carousels extracted\n",
    "    if not hasattr(media, 'carousel_ids'):\n",
    "        media.carousel_ids = ''\n",
    "        media.carousel_types = ''\n",
    "        media.carousel_thumbnail_urls = ''\n",
    "        media.carousel_image_highres_urls = ''\n",
    "\n",
    "    row = [\n",
    "        media.identifier,\n",
    "        media.short_code,\n",
    "        media.link,\n",
    "        media.owner.identifier,\n",
    "        media.owner.username,\n",
    "        media.owner.full_name,\n",
    "        media.type,\n",
    "        media.created_time,\n",
    "        media.likes_count,\n",
    "        media.image_thumbnail_url,\n",
    "        media.image_high_resolution_url,\n",
    "        media.carousel_ids,\n",
    "        media.carousel_types,\n",
    "        media.carousel_thumbnail_urls,\n",
    "        media.carousel_image_highres_urls,\n",
    "        media.caption,\n",
    "        media.comments_count,\n",
    "        media.comments,\n",
    "        media.location_id,  \n",
    "        media.location_name,\n",
    "        media.location_slug,\n",
    "    ]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to convert one and see how this looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = medias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = media_to_row(m)\n",
    "for k, v in zip(columns, sample_row):  # zip allows us to iterate over \"columns\" and \"row\" simultaneously\n",
    "    print(f'[{k}]: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert the rest of the data and create `pandas.Dataframe` (a spreadsheet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = []\n",
    "for m in medias:\n",
    "    rawdata.append(media_to_row(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rawdata, columns=columns)\n",
    "df.head(3)  # sneak peek first three items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as csv\n",
    "data_path = pathlib.Path('tmp/data')\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(data_path / 'london.csv', quotechar=\"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun... lets check what's the most liked photo in this 50 posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=['likes_count'], ascending=False).head(3)\n",
    "for i in range(3):\n",
    "    curr_data = df_sorted.iloc[i]\n",
    "    url = curr_data.img_thumbnail_url\n",
    "    best_thumbnail = get_thumbnail(url)\n",
    "    show_thumbnail(best_thumbnail, f'#{i+1}: {curr_data.likes_count} likes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was it what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note]\n",
    "When our database grows, CSV will no longer be efficient for accessing the data. Eventually we want a proper database. Options are:\n",
    "- SQL,\n",
    "- NoSQL,\n",
    "- GraphQL, \n",
    "- etc..,\n",
    "\n",
    "But we don't want to worry about that now for MVP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
