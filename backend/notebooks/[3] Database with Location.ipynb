{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about these\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('..')\n",
    "from time import sleep\n",
    "\n",
    "from igramscraper.instagram import Instagram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "%matplotlib inline  \n",
    "\n",
    "# import previously defined functions\n",
    "from core.utils import get_thumbnail, show_thumbnail, imresize\n",
    "from core.instagram import get_media_by_url\n",
    "from core.envs import DATA_DIR, IMAGE_DIR, THUMBNAIL_DIR\n",
    "from core.db.persistence import media_to_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Location data\n",
    "- We are not done yet! We need to scrape location information\n",
    "- As we established, scraping too fast will get us blocked. The recommended speed limit is also very slow -- about 30s per request, 10min break between every 10 requests. That's too slow! 60post/hr => dataset of 10,000 = takes 166hr = 1 week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping with ProxyPool \n",
    "\n",
    "- We will speed this up by creating a proxy when we make the request. This is essentially like VPN -- we \"fake\" the origin of where the request is made. In this way, there is no way instagram can block us!\n",
    "- *Is it safe? Not at all. What proxy can do is that they essentially can intercept your information, but also even return you altered messages. Worst case they will send us a virus (Is that even possible @terence? I don't know :D). But these website I'm getting the list of proxy actually also offer monetized service. I imagine they do need trusted proxy servers otherwise they will be sued AF*. Secondly, we are only accessing instagram. It's quite clear what we are trying to get. DO NOT SEND YOUR SENSITIVE INFO!!\n",
    "\n",
    "Source:\n",
    "- https://blog.scrapinghub.com/python-requests-proxy\n",
    "- Free Proxy List: \n",
    "  - https://hidemy.name/en/proxy-list/\n",
    "  - https://www.sslproxies.org/\n",
    "- Paid Proxy List: https://scrapinghub.com/crawlera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias = pd.read_csv(os.path.join(DATA_DIR, 'newyork_20191124.csv'), quotechar=\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igramscraper.instagram import Instagram \n",
    "\n",
    "class ProxyPoolExecutor:\n",
    "    def __init__(self, proxy_pool):\n",
    "        self.proxy_pool = proxy_pool.copy()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _proxy_dict(proxy):\n",
    "        return {\n",
    "            'http': f'http://{proxy}',\n",
    "            'https': f'http://{proxy}',            \n",
    "        }\n",
    "    \n",
    "    def select_proxy(self):\n",
    "        idx = np.random.choice(len(self.proxy_pool))\n",
    "        proxy = self.proxy_pool[idx]\n",
    "        print(f'Selected {proxy}')\n",
    "        return idx, self._proxy_dict(proxy)\n",
    "\n",
    "    def run(self, func, *args, **kwargs):\n",
    "        # until all proxy is down, keep trying\n",
    "        idx, proxy = self.select_proxy()\n",
    "        while self.proxy_pool:\n",
    "            # until all proxy is down, keep trying\n",
    "            idx, proxy = self.select_proxy()\n",
    "            try:\n",
    "                return func(*args, **kwargs, proxy=proxy)\n",
    "            except:\n",
    "                print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                \n",
    "                deleted_proxy = self.proxy_pool.pop(idx)\n",
    "                print(f'{deleted_proxy} no longer works :( removing from the pool')\n",
    "            \n",
    "            if self.is_empty():\n",
    "                raise IndexError('Ran out of valid proxy servers')\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.proxy_pool) == 0\n",
    "\n",
    "    def update_proxy_pool(self, proxy_pool):\n",
    "        self.proxy_pool += proxy_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instagram\n",
    "instagram = Instagram(sleep_between_requests=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create proxy pool executor\n",
    "with open('../data/proxy_pool.txt', 'r') as proxy_file:\n",
    "    proxy_pool = [p.strip() for p in proxy_file.readlines()]\n",
    "\n",
    "executor = ProxyPoolExecutor(proxy_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try one\n",
    "proxy = '182.53.197.202:45661'\n",
    "proxy_dict = ProxyPoolExecutor._proxy_dict(proxy)\n",
    "instagram = Instagram(sleep_between_requests=3)\n",
    "media_obj = get_media_by_url(instagram, medias.iloc[100].media_link, proxy=proxy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_medias = []\n",
    "progress_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the proxy list before running\n",
    "with open('../data/proxy_pool.txt', 'r') as proxy_file:\n",
    "    proxy_pool = [p.strip() for p in proxy_file.readlines()]\n",
    "    \n",
    "executor = ProxyPoolExecutor(proxy_pool)\n",
    "\n",
    "for curr_idx in range(progress_idx+1, len(medias)):\n",
    "    media = medias.iloc[curr_idx]\n",
    "    print(media.media_id)\n",
    "\n",
    "    # scrape media\n",
    "    print('.. scrape media')\n",
    "    media_obj = executor.run(get_media_by_url, instagram, media.media_link)\n",
    "\n",
    "    # scrape media image\n",
    "    print('.. scrape image')\n",
    "    thumbnail = executor.run(get_thumbnail_adapter, media.img_thumbnail_url)\n",
    "\n",
    "    # save the images\n",
    "    imname = f'{IMAGE_DIR}/{media.media_id}.jpeg'\n",
    "    thumbnail_name = f'{THUMBNAIL_DIR}/{media.media_id}.jpeg'\n",
    "    Image.fromarray(thumbnail).save(imname)\n",
    "    Image.fromarray(imresize(thumbnail, (64,64))).save(thumbnail_name)\n",
    "\n",
    "    full_medias.append(media_to_row(media_obj))\n",
    "    progress_idx = curr_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
